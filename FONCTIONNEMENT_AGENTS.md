# Comment Fonctionnent les Agents NomosX ?

**Guide complet pour comprendre le syst√®me**

---

## üéØ S√©lection de Domaines : √âtat Actuel

### Syst√®me de Topics

**Actuellement**, l'utilisateur s√©lectionne ses domaines via le **syst√®me de Topics** :

1. **Page Settings** (`/settings`)
   - L'utilisateur cr√©e des "Topics" (sujets de veille)
   - Chaque Topic a :
     - **Nom** : ex. "Carbon Pricing", "AI in Medicine", "Quantum Computing"
     - **Query** : Mots-cl√©s de recherche (ex. "carbon tax emissions trading")
     - **Tags** : Cat√©gories (ex. "climate, policy, economics")
     - **Description** : D√©tails optionnels

2. **Exemples de Topics**
   ```
   Topic: "Taxe Carbone en Europe"
   Query: "carbon tax european union emissions"
   Tags: ["√©conomie", "√©cologie", "politique"]
   
   Topic: "IA en M√©decine"
   Query: "artificial intelligence medical diagnosis treatment"
   Tags: ["m√©decine", "technologie", "IA"]
   
   Topic: "Physique Quantique Appliqu√©e"
   Query: "quantum computing applications cryptography"
   Tags: ["science", "physique", "technologie"]
   ```

3. **Recherche par Topic**
   - Les agents SCOUT cherchent sur les providers acad√©miques avec les mots-cl√©s du Topic
   - Les r√©sultats sont automatiquement tagu√©s avec les tags du Topic
   - Les briefs g√©n√©r√©s sont associ√©s au Topic

### Ce Qui Manque Actuellement

‚ùå **Pas de s√©lecteur de domaine visuel** (√©conomie, science, √©cologie, m√©decine)
‚ùå **Pas de filtrage par domaine** dans la page Search
‚ùå **Pas de cat√©gories pr√©d√©finies** (l'utilisateur doit cr√©er manuellement les topics)

---

## ü§ñ Comment Fonctionnent les Agents ?

### Vue d'Ensemble

NomosX utilise **10 agents autonomes** qui travaillent en pipeline pour transformer la recherche acad√©mique en intelligence strat√©gique.

```
Query de l'utilisateur
    ‚Üì
[SCOUT] ‚Üí Collecte sources
    ‚Üì
[INDEX] ‚Üí Enrichit identit√©s
    ‚Üì
[RANK] ‚Üí S√©lectionne top sources
    ‚Üì
[READER] ‚Üí Extrait insights
    ‚Üì
[ANALYST] ‚Üí Synth√©tise
    ‚Üì
[CITATION GUARD] ‚Üí Valide
    ‚Üì
[EDITOR] ‚Üí Formate HTML
    ‚Üì
[PUBLISHER] ‚Üí Publie
```

---

### 1. SCOUT Agent üîç

**R√¥le** : Collecter les sources acad√©miques

**Comment √ßa marche** :
1. Re√ßoit une query (ex. "carbon tax impact")
2. Interroge **9 providers** en parall√®le :
   - **OpenAlex** : 28M+ papers scientifiques
   - **Crossref** : 150M+ publications avec DOI
   - **Semantic Scholar** : 200M+ papers IA-index√©s
   - **theses.fr** : Th√®ses fran√ßaises
   - **Unpaywall** : Open access metadata
   - **Eurostat** : Donn√©es macro-√©conomiques
   - **ECB** : Donn√©es Banque Centrale Europ√©enne
   - **INSEE** : Donn√©es √©conomiques fran√ßaises
   - **ROR + ORCID** : Identit√©s institutions/auteurs

3. Pour chaque r√©sultat :
   - Normalise le format
   - Calcule **Quality Score** (0-100)
     - Citation count pond√©r√©
     - Ann√©e de publication (bonus r√©cent)
     - Pr√©sence de DOI
     - Journal impact factor (si disponible)
   - Extrait metadata :
     - Titre, abstract, auteurs
     - Ann√©e, DOI, URL
     - Topics, JEL codes (√©conomie)
   - Enrich avec Unpaywall si DOI pr√©sent (PDF open access)

4. Upsert dans la base de donn√©es (table `Source`)

**Exemple d'output** :
```json
{
  "found": 35,
  "upserted": 33,
  "sourceIds": ["openalex:W123...", "crossref:10.1234/..."]
}
```

---

### 2. INDEX Agent üìä

**R√¥le** : Enrichir les sources avec identit√©s v√©rifi√©es

**Comment √ßa marche** :
1. Re√ßoit une liste de `sourceIds`
2. Pour chaque source :
   
   **A. Traiter les auteurs** :
   - Extrait les noms d'auteurs depuis la source
   - Cherche dans la DB si auteur existe d√©j√† (par nom)
   - Si ORCID disponible dans source :
     - Appelle API ORCID pour r√©cup√©rer profil complet
     - Enrichit : h-index, citation count, affiliations
   - Cr√©e/update record `Author`
   - Cr√©e lien `SourceAuthor` (many-to-many)
   
   **B. Traiter les institutions** :
   - Extrait les affiliations depuis la source
   - Cherche dans la DB si institution existe
   - Si nom d'institution :
     - Appelle API ROR (Research Organization Registry)
     - Match par nom ou ROR ID
     - Enrichit : pays, type (university, research org, company)
   - Cr√©e/update record `Institution`
   - Cr√©e lien `SourceInstitution`
   
   **C. Calculer Novelty Score** :
   - Analyse la combinaison de topics
   - Compare avec sources existantes
   - Score 0-100 (100 = tr√®s novateur)
   - Update `Source.noveltyScore`

**Exemple d'output** :
```json
{
  "enriched": 33,
  "errors": []
}
```

**Effet** : Les sources sont maintenant li√©es √† des auteurs et institutions v√©rifi√©es, avec scores de qualit√© et nouveaut√©.

---

### 3. RANK Agent üèÜ

**R√¥le** : S√©lectionner les meilleures sources

**Comment √ßa marche** :
1. Re√ßoit :
   - `query` : Query originale
   - `limit` : Nombre max de sources (ex. 12)
   - `mode` : "quality" ou "novelty"

2. Query la base de donn√©es :
   ```sql
   SELECT * FROM Source
   WHERE topics LIKE '%carbon%' OR abstract LIKE '%carbon%'
   ORDER BY qualityScore DESC (ou noveltyScore DESC)
   LIMIT 12
   INCLUDE authors, institutions
   ```

3. Retourne les top N sources avec toutes leurs relations

**Exemple d'output** :
```json
[
  {
    "id": "openalex:W123",
    "title": "Carbon Tax Impact on EU Emissions",
    "year": 2024,
    "qualityScore": 92,
    "noveltyScore": 78,
    "authors": [
      { "name": "Dr. Jane Smith", "orcid": "0000-0001-2345-6789" }
    ],
    "institutions": [
      { "name": "MIT", "country": "US" }
    ]
  }
]
```

---

### 4. READER Agent üìñ

**R√¥le** : Extraire les insights cl√©s de chaque source

**Comment √ßa marche** :
1. Re√ßoit la liste des top sources
2. Pour chaque source :
   - Extrait titre + abstract (max 2000 chars)
   - Envoie √† **GPT-4 Turbo** avec prompt structur√© :
     ```
     Extract from this abstract:
     1. Main claims (max 3)
     2. Methods used (max 3)
     3. Key results (max 3)
     4. Limitations (max 2)
     5. Confidence (high/medium/low)
     ```
   - Temperature: 0.1 (tr√®s d√©terministe)
   - Format: JSON structur√©

3. Parse la r√©ponse JSON

**Exemple d'output** :
```json
[
  {
    "sourceId": "openalex:W123",
    "claims": [
      "Carbon tax reduces emissions by 10-15% in first 5 years",
      "Effect varies significantly by sector",
      "Revenue recycling policy matters"
    ],
    "methods": [
      "Difference-in-differences econometric analysis",
      "Panel data from 42 countries (2010-2024)",
      "Robustness checks with synthetic controls"
    ],
    "results": [
      "Average emission reduction: 12.3% (CI: 9.8-14.7%)",
      "Manufacturing sector: -18%, Transport: -8%",
      "No evidence of carbon leakage"
    ],
    "limitations": [
      "Observational data, not RCT",
      "Short-term effects only (5 years)"
    ],
    "confidence": "high"
  }
]
```

---

### 5. ANALYST Agent üß†

**R√¥le** : Synth√©tiser tout en intelligence strat√©gique

**Comment √ßa marche** :
1. Re√ßoit :
   - `question` : Question de recherche de l'utilisateur
   - `sources` : Top sources (avec metadata)
   - `readings` : Output du READER

2. Construit un prompt massif pour GPT-4 Turbo :
   ```
   You are a strategic research analyst for decision-makers.
   
   Question: [question]
   
   Sources:
   [SRC-1] Title, Authors, Year, Abstract, Claims, Methods, Results
   [SRC-2] ...
   [SRC-12] ...
   
   Produce a strategic analysis with:
   1. Executive Summary
   2. Consensus (what researchers agree on)
   3. Disagreements (conflicts in evidence)
   4. Debate:
      - Pro arguments
      - Con arguments
      - Synthesis
   5. Evidence Quality Assessment
   6. Strategic Implications
   7. Risks & Limitations
   8. Open Questions
   9. What Would Change Our Mind
   
   CRITICAL: Cite every claim with [SRC-N] tags.
   ```

3. Temperature: 0.2 (cr√©atif mais stable)
4. Parse la r√©ponse JSON structur√©e

**Exemple d'output** :
```json
{
  "title": "Carbon Tax Impact: Mixed Evidence with Strong Sectoral Variations",
  "summary": "Research consistently shows 10-20% emission reductions [SRC-1][SRC-3], but effects vary significantly by sector [SRC-2]. Revenue recycling policy design is critical [SRC-5].",
  "consensus": "Carbon taxes reduce emissions, with strongest evidence for reductions between 10-20% over 5 years [SRC-1][SRC-3][SRC-7]...",
  "disagreements": "Researchers disagree on carbon leakage effects. [SRC-4] finds significant leakage to non-taxed jurisdictions, while [SRC-9] finds no evidence...",
  "debate": {
    "pro": "Carbon taxes create price signals that drive innovation [SRC-2]...",
    "con": "Regressive effects on low-income households [SRC-6]...",
    "synthesis": "Evidence suggests carbon taxes work when paired with redistribution..."
  },
  "evidence": "High quality: 8/12 studies use robust econometric methods [SRC-1][SRC-3][SRC-7]...",
  "implications": "Policy-makers should consider sector-specific adjustments [SRC-2]...",
  "risks": "Political backlash risk if not paired with visible benefits [SRC-8]...",
  "open_questions": "Optimal tax rate remains debated...",
  "what_changes_mind": "RCT evidence from large-scale carbon tax experiment..."
}
```

---

### 6. CITATION GUARD Agent ‚úÖ

**R√¥le** : Valider que toutes les citations sont correctes

**Comment √ßa marche** :
1. Re√ßoit l'output JSON de l'ANALYST
2. Extrait tous les `[SRC-N]` avec regex
3. V√©rifie :
   - Au moins 1 citation pr√©sente
   - Tous les N sont entre 1 et nombre de sources
   - Pas de `[SRC-13]` si seulement 12 sources
4. Retourne `{ ok: boolean, usedCount: number, invalid: number[] }`

**Si √©chec** :
- Le worker retry l'ANALYST avec prompt renforc√©
- Max 3 tentatives
- Si toujours √©chec ‚Üí job FAILED

---

### 7. EDITOR Agent üé®

**R√¥le** : Transformer le JSON en HTML premium

**Comment √ßa marche** :
1. Re√ßoit :
   - `analysis` : Output de l'ANALYST
   - `sources` : Liste des sources pour r√©f√©rences

2. G√©n√®re HTML avec :
   - Escape HTML entities (s√©curit√©)
   - Structure s√©mantique (`<article>`, `<section>`, `<h2>`)
   - Styling inline (pour emails)
   - D√©bat color√© :
     - Pro : cyan (#5EEAD4)
     - Con : rose (#FB7185)
     - Synthesis : default
   - Liste des sources cit√©es :
     - Num√©rotation [1], [2], [3]
     - Titre, auteurs, ann√©e
     - Lien vers source (DOI ou URL)
     - Provider badge

**Exemple d'output** :
```html
<article style="color: #EDE9E2; background: #0B0E12;">
  <h1>Carbon Tax Impact: Mixed Evidence</h1>
  <section>
    <h2>Executive Summary</h2>
    <p>Research consistently shows 10-20% emission reductions 
       <sup><a href="#src-1">[1]</a></sup>
       <sup><a href="#src-3">[3]</a></sup>...
    </p>
  </section>
  
  <section class="debate">
    <h2>Debate</h2>
    <div class="pro" style="border-left: 3px solid #5EEAD4;">
      <h3>Pro Arguments</h3>
      <p>Carbon taxes create price signals...</p>
    </div>
    <div class="con" style="border-left: 3px solid #FB7185;">
      <h3>Con Arguments</h3>
      <p>Regressive effects on low-income...</p>
    </div>
  </section>
  
  <section class="sources">
    <h2>Sources</h2>
    <ol>
      <li id="src-1">
        <strong>Carbon Tax Impact on EU Emissions</strong><br>
        Smith, J. et al. (2024) ¬∑ OpenAlex ¬∑ QS 92
        <a href="https://doi.org/10.1234/abc">View Source</a>
      </li>
    </ol>
  </section>
</article>
```

---

### 8. PUBLISHER Agent üì§

**R√¥le** : Publier le brief dans la base de donn√©es

**Comment √ßa marche** :
1. Re√ßoit `briefId`
2. Met √† jour le record `Brief` :
   - `publicId = briefId` (ou g√©n√®re ID unique)
   - `updatedAt = now()`
3. Le brief devient accessible √† `/s/[publicId]`

**Effet** : Le brief est maintenant partageable publiquement.

---

### 9. DIGEST Agent üì¨

**R√¥le** : Cr√©er des r√©sum√©s hebdomadaires pour les Topics suivis

**Comment √ßa marche** :
1. Scheduled function (Monday 10 AM UTC)
2. Pour chaque Topic actif :
   - Cherche sources cr√©√©es dans les 7 derniers jours
   - Filtre par query + tags du Topic
   - Rank par qualit√© + novelty
   - Prend top 10 sources
   
3. Envoie √† GPT-4 Turbo :
   ```
   Create a weekly digest for topic: [topic name]
   
   New research this week:
   [List of 10 sources with titles, authors, abstracts]
   
   Generate:
   1. Subject line (email-ready)
   2. Highlight 3-5 most significant sources
   3. For each: "Why it matters"
   4. Signals section (emerging trends)
   
   Format: Email-safe HTML, <500 words
   ```

4. Sauvegarde dans `Digest` table
5. Envoie email aux `AlertSubscription` du Topic

**Exemple d'output** :
```html
<h1>Carbon Pricing ‚Äî Weekly Digest</h1>
<p>3 nouveaux papers majeurs cette semaine</p>

<h2>üî• Top Highlights</h2>
<ol>
  <li>
    <strong>New EU Carbon Border Tax Study</strong><br>
    Why it matters: First empirical evidence of effectiveness...
  </li>
</ol>

<h2>üì° Weak Signals</h2>
<p>Emerging trend: AI-driven carbon accounting...</p>
```

---

### 10. RADAR Agent üì°

**R√¥le** : D√©tecter les signaux faibles et tendances √©mergentes

**Comment √ßa marche** :
1. Cherche sources r√©centes avec **noveltyScore ‚â• 60**
2. Envoie √† GPT-4 Turbo :
   ```
   You are a strategic foresight analyst.
   
   Analyze these high-novelty research papers:
   [List of novel sources]
   
   Identify weak signals (max 5):
   1. Signal title
   2. What we're seeing (evidence)
   3. Why it matters (implications)
   4. Supporting sources [SRC-*]
   5. Confidence (high/medium/low)
   ```

3. Temperature: 0.4 (plus cr√©atif)
4. Parse JSON array de RadarCard

**Exemple d'output** :
```json
[
  {
    "title": "AI-Driven Carbon Accounting Emergence",
    "signal": "3 independent papers in last month propose ML models for real-time carbon tracking [SRC-2][SRC-5][SRC-8]",
    "why_it_matters": "Could enable dynamic carbon pricing and automated compliance, disrupting traditional auditing",
    "sources": ["SRC-2", "SRC-5", "SRC-8"],
    "confidence": "medium"
  }
]
```

---

## üîÑ Orchestration du Pipeline

### Mode S√©quentiel (Full Pipeline)

```typescript
async function runFullPipeline(query: string) {
  // 1. SCOUT
  const { sourceIds } = await scout(query, ["openalex", "crossref"], 20);
  
  // 2. INDEX
  await index(sourceIds);
  
  // 3. DEDUPE (bonus)
  await deduplicateSources();
  
  // 4. RANK
  const topSources = await rank(query, 12, "quality");
  
  // 5. READER
  const readings = await read(topSources);
  
  // 6. ANALYST
  const analysis = await analyst(query, topSources, readings);
  
  // 7. CITATION GUARD
  const guard = citationGuard(analysis, topSources.length);
  if (!guard.ok) throw new Error("Citations invalides");
  
  // 8. EDITOR
  const html = renderBriefHTML(analysis, topSources);
  
  // 9. PUBLISHER
  const brief = await prisma.brief.create({
    data: { question: query, html, sources: topSources.map(s => s.id) }
  });
  
  return { briefId: brief.id };
}
```

### Mode Asynchrone (Job Queue)

```
User cr√©e IngestionRun
    ‚Üì
Job SCOUT (priority 10) ‚Üí DB
    ‚Üì
Worker poll job queue
    ‚Üì
Traite SCOUT ‚Üí Cr√©e job INDEX
    ‚Üì
Worker traite INDEX ‚Üí Cr√©e job RANK
    ‚Üì
...pipeline continue automatiquement
```

**Avantages** :
- R√©silient (retry automatique si √©chec)
- Scalable (multiple workers en parall√®le)
- Tra√ßable (tous les jobs logg√©s dans DB)

---

## üìä D√©terminisme des Agents

| Agent | D√©terminisme | Source de Variance |
|-------|--------------|-------------------|
| SCOUT | Semi | APIs externes (nouveaux papers publi√©s) |
| INDEX | Semi | ROR/ORCID lookups peuvent changer |
| RANK | Full | Requ√™te SQL d√©terministe |
| READER | Semi | LLM (temp=0.1, variance minimale) |
| ANALYST | Semi | LLM (temp=0.2, variance contr√¥l√©e) |
| GUARD | Full | Regex d√©terministe |
| EDITOR | Full | Template HTML fixe |
| PUBLISHER | Full | Upsert DB |
| DIGEST | Semi | LLM (temp=0.3) |
| RADAR | Semi | LLM (temp=0.4, plus cr√©atif) |

---

## üéØ R√©sum√© : Pipeline Complet

**Input** : "Quel est l'impact des taxes carbone ?"

**SCOUT** : Collecte 35 papers depuis OpenAlex, Crossref, etc.

**INDEX** : Enrichit avec 87 auteurs, 42 institutions (ROR/ORCID)

**RANK** : S√©lectionne top 12 sources (Quality Score > 75)

**READER** : Extrait claims/methods/results de chaque paper

**ANALYST** : Synth√©tise en analyse strat√©gique 2000 mots avec citations

**CITATION GUARD** : Valide 18 citations [SRC-1] √† [SRC-12]

**EDITOR** : Transforme en HTML premium avec styling

**PUBLISHER** : Publie √† `/s/abc123`

**Output** : Brief d√©cisionnel pr√™t √† lire üéâ

---

## üí° Forces du Syst√®me

‚úÖ **Autonome** : Pipeline complet sans intervention humaine
‚úÖ **Tra√ßable** : Chaque claim a sa source [SRC-N]
‚úÖ **Robuste** : Retry logic, error handling
‚úÖ **Scalable** : Job queue, multiple workers
‚úÖ **Acad√©mique** : Sources v√©rifi√©es (DOI, ORCID, ROR)
‚úÖ **Multi-sources** : 9 providers couvrant toutes les disciplines
‚úÖ **Intelligent** : GPT-4 Turbo pour synth√®se

---

## üîß Configuration

Tous les agents sont configurables via `lib/agent/pipeline-v2.ts` :

```typescript
const SCOUT_PER_PROVIDER = 20;  // Sources par provider
const RANK_LIMIT = 12;          // Top sources pour analyse
const READER_TEMP = 0.1;        // Temp√©rature LLM (d√©terminisme)
const ANALYST_TEMP = 0.2;       // Temp√©rature LLM
const MAX_JOB_RETRIES = 3;      // Tentatives max avant FAILED
```

---

**NomosX Agents v1.0** ‚Äî Think tank autonome aliment√© par l'IA üöÄ
